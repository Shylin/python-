#### NLTK

NLTK (Natural Language Toolkit) 是著名的Python自然语言处理工具包，但是主要针对的是英文处理。NLTK配套有文档，有语料库，有书籍。



#### 安装步骤

1. 下载NLTK包 `pip install nltk`

2. 运行Python，并输入下面的指令

   ```
    import nltk
    nltk.download()

   ```

3. 弹出下面的窗口，建议安装所有的包 ，即`all`
https://github.com/Shylin/python_nlp/blob/master/images/nltkdownloader.png
   

4. 测试使用：
https://github.com/Shylin/python_nlp/blob/master/images/nltk_test.png


加载book模块所有内容 `from nltk.book import *`



#### NLTK的几个常用函数

1.`text1.concordance("monstrous")`：词语索引视图显示一个指定单词的每一次出现，连同一些上下文一起显示。

```
text1.concordance("monstrous")
Displaying 11 of 11 matches:
ong the former , one was of a most monstrous size . ... This came towards us ,
ON OF THE PSALMS . " Touching that monstrous bulk of the whale or ork we have r
ll over with a heathenish array of monstrous clubs and spears . Some were thick
d as you gazed , and wondered what monstrous cannibal and savage could ever hav
that has survived the flood ; most monstrous and most mountainous ! That Himmal
they might scout at Moby Dick as a monstrous fable , or still worse and more de
th of Radney .'" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l
ing Scenes . In connexion with the monstrous pictures of whales , I am strongly
ere to enter upon those still more monstrous stories of them which are to be fo
ght have been rummaged out of this monstrous cabinet there is no telling . But
of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u

 text1.concordance("lol")
No matches
```

2.`text1.similar("monstrous")`: 出现在相似的上下文中的词

```
text1.similar("monstrous")
true contemptible christian abundant few part mean careful puzzled
mystifying passing curious loving wise doleful gamesome singular
delightfully perilous fearless
```

3.`text2.common_contexts(["monstrous", "very"])`: 两个或两个以上的词共同的上下文

```
text1.common_contexts(["monstrous", "very"])
No common contexts were found

text2.common_contexts(["monstrous", "very"])
a_pretty a_lucky am_glad be_glad is_pretty
```

4.`text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])`: 判断词在文本中的位置,从文本开头算起在它前面有多少词。这个位置信息可以用离散图表示。每一个竖线代表一个单词，每一行代表整个文本。

https://github.com/Shylin/python_nlp/blob/master/images/%E7%A6%BB%E6%95%A3%E5%9B%BE.png

5.`text3.generate()`:产生随机文本, python3中会报错`generate() missing 1 required positional argument: 'words'`

6.`text3.count("smote")`: 统计一个词在文本中出现的次数

7.`fdist1 = FreqDist(text1)`:词频统计,得到一个FreqDist词频对象

```
fdist1 = FreqDist(text1)
In [20]: fdist1
Out[20]:
FreqDist({'[': 3,
          'Moby': 84,
          'Dick': 84,
          'by': 1137,
          ...)

```

8.`fdist1.plot(50, cumulative=True)`: 绘制前50个高频词的词图
https://github.com/Shylin/python_nlp/blob/master/images/%E5%89%8D50%E4%B8%AA%E9%AB%98%E9%A2%91%E8%AF%8D%E5%9B%BE.png


9.`fdist1.hapaxes()`:返回只出现过一次的词

10.`bigrams() ` 实现双连词 

```
In [31]:bigrams(['more', 'is', 'said', 'than', 'done'])
Out[31]: <generator object bigrams at 0x0000027306218BA0> #ython3中是生成器
```

11.`text4.collocations()` 文本的双连词

```
In [36]: text4.collocations()
United States; fellow citizens; four years; years ago; Federal
Government; General Government; American people; Vice President; Old
World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;
God bless; every citizen; Indian tribes; public debt; one another;
foreign nations; political parties
```



#### NLTK 频率分布类中定义的函数

fdist = FreqDist(samples) 创建包含给定样本的频率分布
fdist.inc(sample) 增加样本
fdist['monstrous'] 计数给定样本出现的次数
fdist.freq('monstrous') 给定样本的频率
fdist.N() 样本总数
fdist.keys() 以频率递减顺序排序的样本链表
for sample in fdist: 以频率递减的顺序遍历样本
fdist.max() 数值最大的样本
fdist.tabulate() 绘制频率分布表
fdist.plot() 绘制频率分布图
fdist.plot(cumulative=True) 绘制累积频率分布图
fdist1 < fdist2 测试样本在fdist1 中出现的频率是否小于fdist2



#### 简单对话系统架构
https://github.com/Shylin/python_nlp/blob/master/images/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png


简单的语音对话系统的流程架构：分析语音输入（左上），识别单词，文法分析和在
上下文中解释，应用相关的具体操作（右上）;响应规划，实现文法结构，然后是适当的词
形变化，最后到语音输出；处理的每个过程都蕴含不同类型的语言学知识。

